"""
Early Adopter Model.

Detects companies that discuss emerging technologies BEFORE competitors.
This is a leading indicator of future competitive advantage.

Key Signals:
1. First Mover Score: How early did they adopt new tech language vs peers?
2. Pioneer Score: Combination of breadth and earliness
3. Tech Momentum: Are they accelerating or decelerating tech adoption?
4. Sector Innovation: Sector-specific technology relevance weighting

Sector-Aware Scoring:
- Technologies are weighted by relevance to the company's GICS sector
- Healthcare companies get extra credit for biotech/digital-health adoption
- Financials get extra credit for fintech/blockchain adoption
- Energy gets extra credit for clean-tech/carbon capture
- Cross-sector AI/ML adoption is universally valuable

Research Finding:
- Companies with high pioneer scores (talking about tech early) outperformed
  by +25% over 12 months (p=0.05) in 2023 backtest.
"""

import re
import logging
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple, Set
from collections import defaultdict

from .earnings_tech_signal import (
    EarningsCallTechModel,
    DefeatBetaTranscriptClient,
    TRANSCRIPT_CACHE_PATH,
)

logger = logging.getLogger(__name__)


# ==============================================================================
# EMERGING TECHNOLOGIES LEXICON
# ==============================================================================

# Technologies to track with emergence dates
# Format: tech_id -> {terms, emerged, category, maturity}
EMERGING_TECH_LEXICON = {
    # === AI/ML (Current Wave) ===
    "generative_ai": {
        "terms": ["generative ai", "generative artificial intelligence", "gen ai", "genai"],
        "emerged": "2022-06",
        "category": "AI/ML",
        "maturity": 1,  # 1=emerging, 2=growing, 3=mature
    },
    "large_language_model": {
        "terms": ["large language model", "llm", "llms", "language model", "foundation model"],
        "emerged": "2022-01",
        "category": "AI/ML",
        "maturity": 1,
    },
    "chatgpt": {
        "terms": ["chatgpt", "chat gpt", "gpt-4", "gpt-3", "gpt4", "gpt3", "gpt-5"],
        "emerged": "2022-11",
        "category": "AI/ML",
        "maturity": 1,
    },
    "copilot": {
        "terms": ["copilot", "github copilot", "ai copilot", "ai assistant", "ai agent", "agentic"],
        "emerged": "2021-06",
        "category": "AI/ML",
        "maturity": 1,
    },
    "transformer": {
        "terms": ["transformer model", "transformer architecture", "attention mechanism"],
        "emerged": "2020-01",
        "category": "AI/ML",
        "maturity": 2,
    },
    "inference": {
        "terms": ["inference", "model inference", "ai inference"],
        "emerged": "2020-01",
        "category": "AI/ML",
        "maturity": 2,
    },
    
    # === Cloud/Data ===
    "edge_computing": {
        "terms": ["edge computing", "edge ai", "edge inference", "on-device ai"],
        "emerged": "2018-01",
        "category": "Cloud",
        "maturity": 2,
    },
    "multicloud": {
        "terms": ["multi-cloud", "multicloud", "hybrid cloud"],
        "emerged": "2018-01",
        "category": "Cloud",
        "maturity": 2,
    },
    
    # === Autonomous ===
    "autonomous_vehicle": {
        "terms": ["autonomous vehicle", "self-driving", "robotaxi", "level 4", "level 5", "adas"],
        "emerged": "2016-01",
        "category": "Autonomous",
        "maturity": 2,
    },
    "fsd": {
        "terms": ["full self-driving", "fsd", "autopilot"],
        "emerged": "2019-01",
        "category": "Autonomous",
        "maturity": 2,
    },
    
    # === Semiconductors ===
    "chiplet": {
        "terms": ["chiplet", "chiplets", "advanced packaging", "2.5d", "3d packaging"],
        "emerged": "2020-01",
        "category": "Semiconductors",
        "maturity": 2,
    },
    "advanced_node": {
        "terms": ["3nm", "3 nanometer", "2nm", "2 nanometer", "1nm", "gate-all-around", "gaafet"],
        "emerged": "2021-01",
        "category": "Semiconductors",
        "maturity": 1,
    },
    "hbm": {
        "terms": ["hbm", "high bandwidth memory", "hbm3", "hbm4"],
        "emerged": "2023-01",
        "category": "Semiconductors",
        "maturity": 1,
    },
    
    # === Frontier Tech ===
    "quantum": {
        "terms": ["quantum computing", "quantum computer", "qubit", "quantum supremacy", "quantum advantage"],
        "emerged": "2019-01",
        "category": "Quantum",
        "maturity": 1,
    },
    "metaverse": {
        "terms": ["metaverse", "virtual world", "digital twin", "spatial computing"],
        "emerged": "2021-10",
        "category": "Metaverse",
        "maturity": 2,
    },
    
    # === Biotech ===
    "mrna": {
        "terms": ["mrna", "messenger rna", "mrna technology", "mrna platform"],
        "emerged": "2020-03",
        "category": "Biotech",
        "maturity": 2,
    },
    "crispr": {
        "terms": ["crispr", "gene editing", "gene therapy", "cas9"],
        "emerged": "2017-01",
        "category": "Biotech",
        "maturity": 2,
    },
    
    # === Clean Tech ===
    "carbon_neutral": {
        "terms": ["carbon neutral", "net zero", "carbon negative", "decarbonization", "carbon capture"],
        "emerged": "2019-01",
        "category": "Clean Tech",
        "maturity": 2,
    },
    "solid_state_battery": {
        "terms": ["solid state battery", "solid-state battery", "next-gen battery"],
        "emerged": "2020-01",
        "category": "Clean Tech",
        "maturity": 1,
    },
    
    # === Robotics ===
    "humanoid": {
        "terms": ["humanoid robot", "humanoid", "bipedal robot", "optimus"],
        "emerged": "2022-01",
        "category": "Robotics",
        "maturity": 1,
    },
    
    # === Fintech / Digital Finance ===
    "blockchain": {
        "terms": ["blockchain", "distributed ledger", "smart contract", "smart contracts"],
        "emerged": "2017-01",
        "category": "Fintech",
        "maturity": 2,
    },
    "defi": {
        "terms": ["defi", "decentralized finance", "tokenization", "tokenized assets",
                  "digital assets", "real world assets", "rwa"],
        "emerged": "2020-06",
        "category": "Fintech",
        "maturity": 1,
    },
    "embedded_finance": {
        "terms": ["embedded finance", "banking as a service", "baas", "open banking",
                  "instant payments", "real-time payments"],
        "emerged": "2020-01",
        "category": "Fintech",
        "maturity": 2,
    },
    
    # === Digital Health / MedTech ===
    "digital_health": {
        "terms": ["digital health", "telehealth", "telemedicine", "remote patient monitoring",
                  "digital therapeutics", "dtx"],
        "emerged": "2019-01",
        "category": "Digital Health",
        "maturity": 2,
    },
    "ai_drug_discovery": {
        "terms": ["ai drug discovery", "ai-driven drug", "computational drug",
                  "machine learning drug", "in silico", "ai-powered drug"],
        "emerged": "2020-06",
        "category": "Digital Health",
        "maturity": 1,
    },
    "precision_medicine": {
        "terms": ["precision medicine", "personalized medicine", "companion diagnostic",
                  "biomarker-driven", "genomic medicine"],
        "emerged": "2017-01",
        "category": "Digital Health",
        "maturity": 2,
    },
    
    # === Energy Transition ===
    "hydrogen": {
        "terms": ["green hydrogen", "hydrogen economy", "hydrogen fuel cell",
                  "blue hydrogen", "hydrogen storage", "electrolyzer"],
        "emerged": "2020-01",
        "category": "Energy Transition",
        "maturity": 1,
    },
    "grid_storage": {
        "terms": ["grid-scale storage", "energy storage", "battery storage",
                  "grid modernization", "smart grid", "virtual power plant"],
        "emerged": "2018-01",
        "category": "Energy Transition",
        "maturity": 2,
    },
    "carbon_capture": {
        "terms": ["carbon capture", "ccs", "ccus", "direct air capture",
                  "carbon sequestration", "carbon removal"],
        "emerged": "2019-01",
        "category": "Energy Transition",
        "maturity": 1,
    },
    
    # === Industrial Automation ===
    "industrial_iot": {
        "terms": ["industrial iot", "iiot", "industry 4.0", "smart factory",
                  "smart manufacturing", "connected factory"],
        "emerged": "2017-01",
        "category": "Industrial Automation",
        "maturity": 2,
    },
    "digital_twin_industrial": {
        "terms": ["digital twin", "digital twins", "virtual commissioning",
                  "simulation-driven", "predictive maintenance"],
        "emerged": "2019-01",
        "category": "Industrial Automation",
        "maturity": 2,
    },
    "cobots": {
        "terms": ["collaborative robot", "cobot", "cobots", "autonomous mobile robot",
                  "amr", "warehouse automation", "robotic process"],
        "emerged": "2018-01",
        "category": "Industrial Automation",
        "maturity": 2,
    },
    
    # === Consumer / Retail Tech ===
    "social_commerce": {
        "terms": ["social commerce", "live commerce", "shoppable", "creator economy",
                  "influencer commerce"],
        "emerged": "2020-01",
        "category": "Consumer Tech",
        "maturity": 2,
    },
    "retail_media": {
        "terms": ["retail media", "retail media network", "commerce media",
                  "first-party data", "zero-party data"],
        "emerged": "2021-01",
        "category": "Consumer Tech",
        "maturity": 1,
    },
}

# ==============================================================================
# SECTOR â†’ TECHNOLOGY RELEVANCE MAPPING
# ==============================================================================
# Maps GICS sectors to the tech categories most relevant for innovation scoring.
# Technologies in a company's sector get 2x weight; cross-sector AI/ML gets 1.5x.
# Technologies outside the company's sector still count but at base weight.

SECTOR_TECH_RELEVANCE = {
    "Technology": {
        "high": ["AI/ML", "Cloud", "Semiconductors", "Quantum"],
        "medium": ["Autonomous", "Robotics", "Metaverse", "Industrial Automation"],
    },
    "Communication Services": {
        "high": ["AI/ML", "Metaverse", "Consumer Tech"],
        "medium": ["Cloud", "Quantum"],
    },
    "Healthcare": {
        "high": ["Biotech", "Digital Health"],
        "medium": ["AI/ML", "Quantum"],
    },
    "Financials": {
        "high": ["Fintech", "AI/ML"],
        "medium": ["Cloud", "Quantum"],
    },
    "Energy": {
        "high": ["Energy Transition", "Clean Tech"],
        "medium": ["AI/ML", "Industrial Automation"],
    },
    "Industrials": {
        "high": ["Industrial Automation", "Robotics"],
        "medium": ["AI/ML", "Autonomous", "Clean Tech", "Energy Transition"],
    },
    "Consumer Discretionary": {
        "high": ["Consumer Tech", "AI/ML"],
        "medium": ["Autonomous", "Robotics", "Metaverse"],
    },
    "Consumer Staples": {
        "high": ["Consumer Tech"],
        "medium": ["AI/ML", "Industrial Automation", "Clean Tech"],
    },
    "Materials": {
        "high": ["Clean Tech", "Industrial Automation"],
        "medium": ["AI/ML", "Energy Transition"],
    },
    "Utilities": {
        "high": ["Energy Transition", "Clean Tech"],
        "medium": ["AI/ML", "Industrial Automation"],
    },
    "Real Estate": {
        "high": ["Clean Tech"],
        "medium": ["AI/ML", "Industrial Automation"],
    },
}


# ==============================================================================
# PRE-COMPUTED INDUSTRY BASELINES
# ==============================================================================
# These are approximate median adoption dates across S&P 500 tech companies
# to avoid expensive computation during ranking. Updated periodically.
# Format: tech_id -> approximate industry median adoption date

INDUSTRY_BASELINE_DATES = {
    # AI/ML (most relevant for 2024-2026)
    "generative_ai": "2023-06",
    "large_language_model": "2023-03",
    "chatgpt": "2023-03",
    "copilot": "2023-09",
    "transformer": "2022-06",
    "inference": "2022-01",
    # Cloud
    "edge_computing": "2020-06",
    "multicloud": "2020-01",
    # Autonomous
    "autonomous_vehicle": "2018-06",
    "fsd": "2020-06",
    # Semiconductors
    "chiplet": "2022-06",
    "advanced_node": "2023-01",
    "hbm": "2023-09",
    # Frontier
    "quantum": "2021-06",
    "metaverse": "2022-06",
    # Biotech
    "mrna": "2021-06",
    "crispr": "2020-01",
    # Clean Tech
    "carbon_neutral": "2021-06",
    "solid_state_battery": "2023-01",
    # Robotics
    "humanoid": "2023-06",
    # Fintech
    "blockchain": "2018-06",
    "defi": "2021-06",
    "embedded_finance": "2021-01",
    # Digital Health
    "digital_health": "2020-06",
    "ai_drug_discovery": "2022-01",
    "precision_medicine": "2019-06",
    # Energy Transition
    "hydrogen": "2021-06",
    "grid_storage": "2020-01",
    "carbon_capture": "2021-01",
    # Industrial Automation
    "industrial_iot": "2019-06",
    "digital_twin_industrial": "2021-01",
    "cobots": "2020-06",
    # Consumer Tech
    "social_commerce": "2021-06",
    "retail_media": "2022-06",
}

# Recency weights - how much to weight adoptions by age
# Recent adoptions matter more for investment signals
RECENCY_HALF_LIFE_MONTHS = 24  # Adoption value halves every 2 years


# ==============================================================================
# DATA CLASSES
# ==============================================================================

@dataclass
class TechAdoption:
    """Record of when a company first mentioned a technology."""
    ticker: str
    tech_id: str
    tech_name: str
    category: str
    first_mention_date: datetime
    first_mention_quarter: str
    context: str
    industry_avg_date: Optional[datetime] = None
    lead_months: Optional[float] = None


@dataclass
class EarlyAdopterSignal:
    """Signal output from the Early Adopter Model."""
    ticker: str
    analysis_date: datetime
    
    # Core metrics
    pioneer_score: float  # 0-1 combined score
    total_techs_adopted: int  # How many emerging techs they discuss
    techs_adopted_early: int  # How many they discussed BEFORE industry avg
    avg_lead_months: float  # Average months ahead of industry
    
    # Breakdown by category
    categories: Dict[str, int]  # category -> count of early adoptions
    
    # Top adoptions (most ahead of curve)
    earliest_adoptions: List[TechAdoption]
    
    # Signal interpretation
    signal: str  # "strong_buy", "buy", "neutral", "avoid"
    signal_strength: float  # -1 to +1
    
    # GenAI specific (most relevant current wave)
    genai_score: float  # Lead months on GenAI-related terms
    genai_adopted: List[str]  # Which GenAI terms they've adopted
    
    # Sector-aware scoring
    detected_sector: str = ""  # GICS sector detected for this ticker
    sector_innovation_score: float = 0.0  # 0-1 score for sector-relevant innovation
    sector_relevant_techs: List[str] = field(default_factory=list)  # Sector-relevant techs adopted


@dataclass
class IndustryTimeline:
    """When technologies were adopted across the industry."""
    tech_id: str
    first_adopter: str
    first_date: datetime
    median_date: datetime
    adoption_count: int
    adopters: List[Tuple[str, datetime]]  # List of (ticker, date) sorted by date


# ==============================================================================
# EARLY ADOPTER MODEL
# ==============================================================================

class EarlyAdopterModel:
    """
    Detects companies that discuss emerging technologies before competitors.
    
    This is a leading indicator of future competitive advantage.
    Companies that talk about new tech early are often investing ahead
    of the curve.
    
    Usage:
        model = EarlyAdopterModel()
        
        # Fast mode (default) - only loads transcripts for target ticker
        signal = model.analyze_company("NVDA")
        print(f"Pioneer Score: {signal.pioneer_score}")
        
        # Full mode - compares against peer universe (slower)
        signal = model.analyze_company("NVDA", fast_mode=False)
        
        # Get industry-wide view
        timelines = model.get_industry_timelines()
        
        # Rank all companies by pioneer score
        rankings = model.rank_pioneers(["NVDA", "MSFT", "AAPL", ...])
    """
    
    # Class-level cache limits to prevent unbounded memory growth
    _max_adoption_cache_size = 20
    _adoption_cache_order: List[str] = []
    
    # Class-level industry baseline cache (shared across instances)
    _precomputed_baselines: Dict[str, datetime] = {}
    
    def __init__(self, lookback_years: int = 3, focus_recent: bool = True):
        """
        Initialize the model.
        
        Args:
            lookback_years: How many years of history to analyze (default: 3 for recency)
            focus_recent: If True, apply recency decay to older adoptions
        """
        self.lookback_years = lookback_years
        self.focus_recent = focus_recent
        self.client = DefeatBetaTranscriptClient()
        self.lexicon = EMERGING_TECH_LEXICON
        
        # Compiled patterns
        self._patterns = {}
        self._compile_patterns()
        
        # Caches with LRU eviction
        self._adoption_cache: Dict[str, List[TechAdoption]] = {}
        self._timeline_cache: Dict[str, IndustryTimeline] = {}
        self._industry_avgs: Dict[str, datetime] = {}
        
        # Load precomputed baselines if not already loaded
        self._load_precomputed_baselines()
        
        logger.info("EarlyAdopterModel initialized")
    
    def _load_precomputed_baselines(self):
        """Load pre-computed industry baseline dates."""
        if not EarlyAdopterModel._precomputed_baselines:
            for tech_id, date_str in INDUSTRY_BASELINE_DATES.items():
                try:
                    EarlyAdopterModel._precomputed_baselines[tech_id] = datetime.strptime(date_str, "%Y-%m")
                except:
                    pass
            logger.debug(f"Loaded {len(EarlyAdopterModel._precomputed_baselines)} precomputed baselines")
    
    def _apply_recency_decay(self, adoption_date: datetime, lead_months: float) -> float:
        """Apply decay to weight recent adoptions more heavily."""
        if not self.focus_recent:
            return lead_months
        
        # Calculate months since adoption
        months_ago = (datetime.now() - adoption_date).days / 30.44
        
        # Exponential decay: value = lead_months * 0.5^(months_ago / half_life)
        decay_factor = 0.5 ** (months_ago / RECENCY_HALF_LIFE_MONTHS)
        
        # Also boost maturity=1 (emerging) techs
        return lead_months * decay_factor
    
    def clear_cache(self):
        """Clear all caches to free memory."""
        self._adoption_cache.clear()
        self._timeline_cache.clear()
        self._industry_avgs.clear()
        EarlyAdopterModel._adoption_cache_order.clear()
        # Also clear transcript cache
        self.client.clear_cache()
        import gc
        gc.collect()
        logger.info("EarlyAdopterModel caches cleared")
    
    def _detect_sector(self, ticker: str) -> str:
        """Detect GICS sector for a ticker using sector_momentum's lookup."""
        try:
            from auto_researcher.models.sector_momentum import TICKER_SECTORS
            if ticker.upper() in TICKER_SECTORS:
                return TICKER_SECTORS[ticker.upper()]
        except ImportError:
            pass
        
        # Fallback: try yfinance
        try:
            import yfinance as yf
            info = yf.Ticker(ticker).info
            return info.get("sector", "")
        except Exception:
            pass
        return ""
    
    def _get_sector_weight(self, category: str, sector: str) -> float:
        """Get the relevance weight for a tech category given the company's sector.
        
        Returns:
            2.0 for high-relevance sector tech
            1.5 for medium-relevance sector tech  
            1.0 for any other tech (baseline)
        """
        if not sector or sector not in SECTOR_TECH_RELEVANCE:
            return 1.0
        
        relevance = SECTOR_TECH_RELEVANCE[sector]
        if category in relevance.get("high", []):
            return 2.0
        elif category in relevance.get("medium", []):
            return 1.5
        return 1.0
    
    def _compile_patterns(self):
        """Compile regex patterns for each technology."""
        for tech_id, config in self.lexicon.items():
            terms = config["terms"]
            pattern = r'\b(' + '|'.join(re.escape(t) for t in terms) + r')\b'
            self._patterns[tech_id] = re.compile(pattern, re.IGNORECASE)
    
    def _load_transcripts(self, ticker: str) -> List[Dict]:
        """Load all transcripts for a ticker."""
        # Use high limit to get full history
        return self.client.get_transcripts(ticker, limit=100)
    
    def _find_first_mentions(self, ticker: str) -> List[TechAdoption]:
        """Find when a company first mentioned each technology."""
        
        if ticker in self._adoption_cache:
            return self._adoption_cache[ticker]
        
        transcripts = self._load_transcripts(ticker)
        
        if not transcripts:
            self._adoption_cache[ticker] = []
            return []
        
        # Sort chronologically (oldest first)
        transcripts = sorted(transcripts, key=lambda x: x.get("date", ""))
        
        first_mentions = {}
        
        for t in transcripts:
            try:
                content = t.get("content", "")
                date_str = t.get("date", "")[:10]
                date = datetime.strptime(date_str, "%Y-%m-%d")
                quarter = f"Q{t.get('quarter', 1)} {t.get('year', 2024)}"
                
                for tech_id, pattern in self._patterns.items():
                    # Skip if already found
                    if tech_id in first_mentions:
                        continue
                    
                    match = pattern.search(content)
                    if match:
                        # Get context
                        start = max(0, match.start() - 100)
                        end = min(len(content), match.end() + 100)
                        context = content[start:end].strip()
                        
                        config = self.lexicon[tech_id]
                        
                        first_mentions[tech_id] = TechAdoption(
                            ticker=ticker,
                            tech_id=tech_id,
                            tech_name=tech_id.replace("_", " ").title(),
                            category=config["category"],
                            first_mention_date=date,
                            first_mention_quarter=quarter,
                            context=context,
                        )
            except Exception as e:
                logger.debug(f"Error processing transcript: {e}")
                continue
        
        result = list(first_mentions.values())
        self._adoption_cache[ticker] = result
        return result
    
    def build_industry_timelines(
        self, 
        tickers: List[str],
        min_date: Optional[datetime] = None,
    ) -> Dict[str, IndustryTimeline]:
        """
        Build adoption timelines for each technology across the industry.
        
        This calculates when each tech was first mentioned and the median
        adoption date across all companies.
        """
        
        if min_date is None:
            min_date = datetime.now() - timedelta(days=365 * self.lookback_years)
        
        # Collect all adoptions
        tech_adoptions: Dict[str, List[Tuple[str, datetime]]] = defaultdict(list)
        
        for ticker in tickers:
            adoptions = self._find_first_mentions(ticker)
            for a in adoptions:
                if a.first_mention_date >= min_date:
                    tech_adoptions[a.tech_id].append((ticker, a.first_mention_date))
        
        # Build timelines
        timelines = {}
        
        for tech_id, adopters in tech_adoptions.items():
            if not adopters:
                continue
            
            # Sort by date
            adopters = sorted(adopters, key=lambda x: x[1])
            
            # Calculate median
            dates = [d for _, d in adopters]
            median_idx = len(dates) // 2
            median_date = dates[median_idx]
            
            timelines[tech_id] = IndustryTimeline(
                tech_id=tech_id,
                first_adopter=adopters[0][0],
                first_date=adopters[0][1],
                median_date=median_date,
                adoption_count=len(adopters),
                adopters=adopters,
            )
            
            # Cache industry average
            self._industry_avgs[tech_id] = median_date
        
        self._timeline_cache = timelines
        return timelines
    
    def _calculate_lead_times(self, adoptions: List[TechAdoption], use_precomputed: bool = False) -> List[TechAdoption]:
        """Calculate how many months ahead each adoption was."""
        # Use precomputed baselines in fast mode
        baselines = EarlyAdopterModel._precomputed_baselines if use_precomputed else self._industry_avgs
        
        for adoption in adoptions:
            if adoption.tech_id in baselines:
                avg_date = baselines[adoption.tech_id]
                adoption.industry_avg_date = avg_date
                
                delta = avg_date - adoption.first_mention_date
                adoption.lead_months = delta.days / 30.44
        
        return adoptions
    
    def analyze_company(
        self, 
        ticker: str,
        industry_tickers: Optional[List[str]] = None,
        fast_mode: bool = True,
    ) -> EarlyAdopterSignal:
        """
        Analyze a company's early adopter behavior.
        
        Args:
            ticker: Stock ticker to analyze
            industry_tickers: List of peer companies for comparison.
                             If None, uses a default tech universe.
            fast_mode: If True, use precomputed industry baselines (much faster).
                      If False, compute from peer transcripts (more accurate).
        
        Returns:
            EarlyAdopterSignal with pioneer score and details
        """
        
        # Fast mode: Only load target ticker transcripts, use precomputed baselines
        if fast_mode:
            return self._analyze_company_fast(ticker)
        
        # Full mode: Load all peer transcripts for accurate comparison
        # Default peer universe
        if industry_tickers is None:
            industry_tickers = [
                "NVDA", "AAPL", "MSFT", "GOOGL", "META", "AMZN", "TSLA",
                "AMD", "INTC", "AVGO", "QCOM", "TXN", "MU",
                "CRM", "ADBE", "ORCL", "NOW", "SNOW", "PLTR",
                "IBM", "CSCO", "DELL",
            ]
        
        # Detect sector
        sector = self._detect_sector(ticker)
        
        # Ensure target ticker is in the list
        if ticker not in industry_tickers:
            industry_tickers = [ticker] + industry_tickers
        
        # Build industry timelines if not cached
        if not self._timeline_cache:
            self.build_industry_timelines(industry_tickers)
        
        # Get adoptions for this ticker
        adoptions = self._find_first_mentions(ticker)
        
        if not adoptions:
            return EarlyAdopterSignal(
                ticker=ticker,
                analysis_date=datetime.now(),
                pioneer_score=0.0,
                total_techs_adopted=0,
                techs_adopted_early=0,
                avg_lead_months=0.0,
                categories={},
                earliest_adoptions=[],
                signal="neutral",
                signal_strength=0.0,
                genai_score=0.0,
                genai_adopted=[],
                detected_sector=sector,
            )
        
        # Calculate lead times (full mode uses computed baselines)
        adoptions = self._calculate_lead_times(adoptions, use_precomputed=False)
        
        return self._compute_signal(ticker, adoptions, sector=sector)
    
    def _analyze_company_fast(self, ticker: str) -> EarlyAdopterSignal:
        """
        Fast analysis using only target ticker transcripts and precomputed baselines.
        
        This is ~20x faster than full mode as it doesn't load peer transcripts.
        """
        # Detect sector for sector-aware scoring
        sector = self._detect_sector(ticker)
        
        # Get adoptions for this ticker only
        adoptions = self._find_first_mentions(ticker)
        
        if not adoptions:
            return EarlyAdopterSignal(
                ticker=ticker,
                analysis_date=datetime.now(),
                pioneer_score=0.0,
                total_techs_adopted=0,
                techs_adopted_early=0,
                avg_lead_months=0.0,
                categories={},
                earliest_adoptions=[],
                signal="neutral",
                signal_strength=0.0,
                genai_score=0.0,
                genai_adopted=[],
                detected_sector=sector,
            )
        
        # Calculate lead times using precomputed baselines
        adoptions = self._calculate_lead_times(adoptions, use_precomputed=True)
        
        return self._compute_signal(ticker, adoptions, sector=sector)
    
    def _compute_signal(self, ticker: str, adoptions: List[TechAdoption], sector: str = "") -> EarlyAdopterSignal:
        """Compute the early adopter signal from adoptions, with sector-aware weighting."""
        
        # Filter to only recent adoptions (within lookback window)
        min_date = datetime.now() - timedelta(days=365 * self.lookback_years)
        recent_adoptions = [a for a in adoptions if a.first_mention_date >= min_date]
        
        if not recent_adoptions:
            # Fall back to all adoptions if none are recent
            recent_adoptions = adoptions
        
        # Count early adoptions (before industry median)
        early_adoptions = [a for a in recent_adoptions if a.lead_months and a.lead_months > 0]
        
        # Apply recency decay to lead times for scoring
        weighted_lead_times = []
        sector_weighted_lead_times = []
        sector_relevant_techs = []
        
        for a in recent_adoptions:
            if a.lead_months is not None:
                # Apply recency decay
                decayed_lead = self._apply_recency_decay(a.first_mention_date, a.lead_months)
                weighted_lead_times.append(decayed_lead)
                
                # Apply sector relevance weight
                sector_weight = self._get_sector_weight(a.category, sector)
                sector_weighted_lead_times.append(decayed_lead * sector_weight)
                
                if sector_weight >= 1.5:
                    sector_relevant_techs.append(a.tech_id)
        
        avg_lead = sum(weighted_lead_times) / len(weighted_lead_times) if weighted_lead_times else 0
        
        # Categories (from early adoptions)
        categories = defaultdict(int)
        for a in early_adoptions:
            categories[a.category] += 1
        
        # Pioneer score with recency-weighted components
        # Focus more on emerging tech (maturity=1)
        emerging_techs = [a for a in recent_adoptions if self.lexicon.get(a.tech_id, {}).get("maturity") == 1]
        
        breadth_score = min(len(recent_adoptions) / 8, 1.0)  # Max at 8 techs (reduced from 12)
        emerging_score = min(len(emerging_techs) / 4, 1.0)  # Bonus for emerging tech
        earliness_score = min(max(avg_lead / 12, 0), 1.0)  # Max at 12 months ahead (reduced from 18)
        
        # Sector innovation score: weighted by sector relevance
        if sector and sector_weighted_lead_times:
            # How many sector-relevant techs adopted early?
            sector_early = [a for a in early_adoptions 
                          if self._get_sector_weight(a.category, sector) >= 1.5]
            sector_breadth = min(len(sector_relevant_techs) / 4, 1.0)
            sector_earliness = (sum(sector_weighted_lead_times) / len(sector_weighted_lead_times) / 12)
            sector_earliness = min(max(sector_earliness, 0), 1.0)
            sector_innovation_score = 0.5 * sector_breadth + 0.5 * sector_earliness
        else:
            sector_innovation_score = 0.0
        
        # Weighted combination: blend base pioneer score with sector innovation
        # If sector is known, sector_innovation contributes 25% of final score
        if sector and sector_innovation_score > 0:
            base_pioneer = 0.3 * breadth_score + 0.4 * emerging_score + 0.3 * earliness_score
            pioneer_score = 0.75 * base_pioneer + 0.25 * sector_innovation_score
        else:
            pioneer_score = 0.3 * breadth_score + 0.4 * emerging_score + 0.3 * earliness_score
        
        # GenAI-specific score (most relevant current wave)
        genai_techs = ["generative_ai", "large_language_model", "chatgpt", "copilot", "inference"]
        genai_lead = 0
        genai_adopted = []
        for a in recent_adoptions:
            if a.tech_id in genai_techs:
                decayed = self._apply_recency_decay(a.first_mention_date, a.lead_months or 0)
                genai_lead += decayed
                genai_adopted.append(a.tech_id)
        
        # Sort adoptions by decayed lead time (sector-weighted)
        for a in recent_adoptions:
            base_decayed = self._apply_recency_decay(a.first_mention_date, a.lead_months or 0)
            sector_w = self._get_sector_weight(a.category, sector) if sector else 1.0
            a._decayed_lead = base_decayed * sector_w
        sorted_adoptions = sorted(recent_adoptions, key=lambda x: -(getattr(x, '_decayed_lead', 0)))
        
        # Signal interpretation
        if pioneer_score >= 0.7:
            signal = "strong_buy"
            signal_strength = 0.8 + 0.2 * (pioneer_score - 0.7) / 0.3
        elif pioneer_score >= 0.5:
            signal = "buy"
            signal_strength = 0.4 + 0.4 * (pioneer_score - 0.5) / 0.2
        elif pioneer_score >= 0.3:
            signal = "neutral"
            signal_strength = 0.0
        else:
            signal = "avoid"
            signal_strength = -0.3
        
        return EarlyAdopterSignal(
            ticker=ticker,
            analysis_date=datetime.now(),
            pioneer_score=pioneer_score,
            total_techs_adopted=len(adoptions),
            techs_adopted_early=len(early_adoptions),
            avg_lead_months=avg_lead,
            categories=dict(categories),
            earliest_adoptions=sorted_adoptions[:5],
            signal=signal,
            signal_strength=signal_strength,
            genai_score=genai_lead,
            genai_adopted=genai_adopted,
            detected_sector=sector,
            sector_innovation_score=sector_innovation_score,
            sector_relevant_techs=sector_relevant_techs,
        )
    
    def rank_pioneers(
        self, 
        tickers: List[str],
    ) -> List[EarlyAdopterSignal]:
        """
        Rank all tickers by their pioneer score.
        
        Args:
            tickers: List of tickers to analyze
            
        Returns:
            List of signals sorted by pioneer score (highest first)
        """
        
        # Build industry timelines
        self.build_industry_timelines(tickers)
        
        # Analyze each ticker
        signals = []
        for ticker in tickers:
            try:
                signal = self.analyze_company(ticker, industry_tickers=tickers)
                signals.append(signal)
            except Exception as e:
                logger.warning(f"Failed to analyze {ticker}: {e}")
                continue
        
        # Sort by pioneer score
        signals.sort(key=lambda x: -x.pioneer_score)
        
        return signals
    
    def get_first_movers(self, tech_id: str) -> List[Tuple[str, datetime, float]]:
        """
        Get the first movers for a specific technology.
        
        Args:
            tech_id: Technology ID from EMERGING_TECH_LEXICON
            
        Returns:
            List of (ticker, first_mention_date, lead_months) tuples
        """
        if tech_id not in self._timeline_cache:
            raise ValueError(f"Unknown tech_id: {tech_id}. Build timelines first.")
        
        timeline = self._timeline_cache[tech_id]
        median = timeline.median_date
        
        result = []
        for ticker, date in timeline.adopters:
            lead_months = (median - date).days / 30.44
            result.append((ticker, date, lead_months))
        
        return result
    
    def get_emerging_now(self) -> List[str]:
        """
        Get technologies that are currently in the emerging phase (maturity=1).
        
        These are the most relevant for detecting early adopters right now.
        """
        return [
            tech_id for tech_id, config in self.lexicon.items()
            if config["maturity"] == 1
        ]
    
    def get_summary(self, signal: EarlyAdopterSignal) -> str:
        """Generate human-readable summary."""
        lines = [f"Early Adopter Analysis: {signal.ticker}"]
        lines.append("=" * 50)
        
        lines.append(f"\nPioneer Score: {signal.pioneer_score:.2f}")
        lines.append(f"Signal: {signal.signal.upper()} (strength: {signal.signal_strength:+.2f})")
        
        lines.append(f"\nTechnologies Adopted: {signal.total_techs_adopted}")
        lines.append(f"Adopted Early (before industry): {signal.techs_adopted_early}")
        lines.append(f"Average Lead Time: {signal.avg_lead_months:+.1f} months")
        
        if signal.categories:
            lines.append("\nCategories Pioneered:")
            for cat, count in sorted(signal.categories.items(), key=lambda x: -x[1]):
                lines.append(f"  {cat}: {count}")
        
        if signal.genai_adopted:
            lines.append(f"\nGenAI Score: {signal.genai_score:+.1f} months ahead")
            lines.append(f"GenAI Terms: {', '.join(signal.genai_adopted)}")
        
        if signal.earliest_adoptions:
            lines.append("\nTop Early Adoptions:")
            for a in signal.earliest_adoptions[:3]:
                lines.append(f"  {a.tech_name}: {a.first_mention_date.strftime('%Y-%m')} (+{a.lead_months:.0f}mo)")
        
        return "\n".join(lines)


# ==============================================================================
# CONVENIENCE FUNCTIONS
# ==============================================================================

def find_early_adopters(
    tickers: List[str],
    min_pioneer_score: float = 0.5,
) -> List[EarlyAdopterSignal]:
    """
    Find companies that are early adopters of emerging technologies.
    
    Args:
        tickers: List of tickers to analyze
        min_pioneer_score: Minimum pioneer score to include (0-1)
        
    Returns:
        List of signals for companies meeting the threshold
    """
    model = EarlyAdopterModel()
    signals = model.rank_pioneers(tickers)
    
    return [s for s in signals if s.pioneer_score >= min_pioneer_score]


def get_genai_pioneers(tickers: List[str], top_n: int = 10) -> List[EarlyAdopterSignal]:
    """
    Find the top GenAI early adopters.
    
    Args:
        tickers: List of tickers to analyze
        top_n: Number of top pioneers to return
        
    Returns:
        Top N signals sorted by GenAI score
    """
    model = EarlyAdopterModel()
    model.build_industry_timelines(tickers)
    
    signals = []
    for ticker in tickers:
        signal = model.analyze_company(ticker, industry_tickers=tickers)
        if signal.genai_adopted:  # Only include those with GenAI mentions
            signals.append(signal)
    
    signals.sort(key=lambda x: -x.genai_score)
    return signals[:top_n]
