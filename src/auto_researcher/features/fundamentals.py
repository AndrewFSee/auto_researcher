"""
Fundamental feature engineering.

This module provides functions to compute fundamental factors for cross-sectional
equity analysis. Supports five factor families:

1. VALUE: Earnings yield, book-to-price, sales-to-price
2. QUALITY: ROE, ROA, net margin
3. GROWTH: Revenue growth, EPS growth
4. PROFITABILITY: Gross margin, operating margin
5. SIZE: Log market cap

Data Loading:
-------------
The `load_raw_fundamentals` function can load data from:
- A CSV file with columns: date, ticker, market_cap, pe_ratio, pb_ratio, etc.
- SEC EDGAR via finagg (requires finagg package and SEC credentials)
- A fallback "mock" mode that returns NaNs or simple placeholders for testing

To integrate REAL fundamental data:
1. Provide a CSV with the required schema, OR
2. Use finagg to fetch SEC EDGAR data (set source="finagg"), OR
3. Modify `load_raw_fundamentals` to call your preferred API
   (e.g., SimFin, Alpha Vantage, Polygon.io, Quandl)

Cross-Sectional Processing:
---------------------------
All factors are processed cross-sectionally by date:
- Optional winsorization at configurable percentile tails
- Optional z-score normalization (mean=0, std=1)
"""

import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import Literal

import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)


# =============================================================================
# Configuration
# =============================================================================


@dataclass
class FundamentalFactorConfig:
    """
    Configuration for fundamental factor computation.

    Attributes:
        use_value: Include value factors (earnings yield, book-to-price, sales-to-price).
        use_quality: Include quality factors (ROE, ROA, net margin).
        use_growth: Include growth factors (revenue growth, EPS growth).
        use_profitability: Include profitability factors (gross margin, operating margin).
        use_size: Include size factor (log market cap).
        winsorize_pct: Percentile for winsorization (0.01 = 1% tails). Set to 0 to disable.
        zscore_by_cross_section: Whether to z-score factors within each date.
        source: Data source to use ("csv", "finagg", or "yfinance").
        csv_path: Path to CSV file (required if source="csv").
        finagg_mode: Mode for finagg data ("quarterly_refined", "quarterly_api", "annual_refined").
            - "quarterly_refined": Use local SQL database (faster, requires finagg install)
            - "quarterly_api": Fetch directly from SEC API (slower, no local DB needed)
            - "annual_refined": Annual data from local SQL database
    """

    use_value: bool = True
    use_quality: bool = True
    use_growth: bool = True
    use_profitability: bool = True
    use_size: bool = True
    winsorize_pct: float = 0.01  # 1% tails
    zscore_by_cross_section: bool = True
    
    # Data source configuration
    source: Literal["csv", "finagg", "yfinance"] = "csv"
    csv_path: Path | str | None = None
    finagg_mode: Literal["quarterly_refined", "quarterly_api", "annual_refined"] = "quarterly_refined"


# Raw fundamental columns expected in input data
RAW_FUNDAMENTAL_COLUMNS = [
    "market_cap",
    "pe_ratio",
    "pb_ratio",
    "ps_ratio",
    "dividend_yield",
    "roe",
    "roa",
    "gross_margin",
    "operating_margin",
    "net_margin",
    "revenue_ttm",
    "revenue_growth_1y",
    "eps_ttm",
    "eps_growth_1y",
]


# =============================================================================
# Data Loading
# =============================================================================


def load_raw_fundamentals(
    tickers: list[str],
    start: str,
    end: str,
    fundamentals_csv_path: str | None = None,
    use_yfinance: bool = True,
    config: FundamentalFactorConfig | None = None,
) -> pd.DataFrame:
    """
    Load raw fundamental data for a set of tickers.

    Returns a DataFrame with MultiIndex (date, ticker) and columns for each
    fundamental metric.

    Data source priority (when config.source is not specified or "csv"):
    1. If fundamentals_csv_path is provided and file exists, load from CSV
    2. If use_yfinance=True (default), fetch from yfinance (limited history)
    3. Otherwise, return placeholder DataFrame with NaNs

    When config.source="finagg":
    - Fetches data from SEC EDGAR via finagg library
    - Requires finagg to be installed and SEC credentials configured

    Args:
        tickers: List of ticker symbols to load.
        start: Start date in 'YYYY-MM-DD' format.
        end: End date in 'YYYY-MM-DD' format.
        fundamentals_csv_path: Path to CSV file with fundamental data.
            The CSV should have been generated by scripts/download_fundamentals.py
            using FMP (Financial Modeling Prep) and Alpha Vantage APIs.
            Expected schema:
                date, ticker, market_cap, pe_ratio, pb_ratio, ps_ratio,
                dividend_yield, roe, roa, gross_margin, operating_margin,
                net_margin, revenue_ttm, revenue_growth_1y, eps_ttm, eps_growth_1y
        use_yfinance: If True, fetch fundamentals from yfinance when no CSV provided.
            Note: yfinance only provides ~4-5 quarters of history.
        config: FundamentalFactorConfig specifying data source and options.
            If provided, config.source determines the data source:
            - "csv": Use CSV file (default behavior)
            - "finagg": Fetch from SEC EDGAR via finagg
            - "yfinance": Fetch from yfinance

    Returns:
        DataFrame with MultiIndex (date, ticker) and fundamental columns.

    Notes:
        For production backtests with deep historical data, use the download script:
        
            python scripts/download_fundamentals.py \\
                --universe largecap \\
                --start-year 2005 \\
                --end-year 2024 \\
                --output-csv data/fundamentals_largecap.csv
        
        Then pass the CSV path to this function.
        
        Alternatively, use finagg for SEC EDGAR data:
        
            pip install finagg
            export SEC_API_USER_AGENT="Your Name email@example.com"
            # Then use config=FundamentalFactorConfig(source="finagg")

    Example CSV format:
        date,ticker,market_cap,pe_ratio,pb_ratio,ps_ratio,...
        2023-01-31,AAPL,2500000000000,25.5,40.2,6.8,...
        2023-01-31,MSFT,2200000000000,32.1,12.5,10.2,...
    """
    # Determine source from config if provided
    source = "csv"  # Default
    if config is not None:
        source = config.source
        # Override csv_path from config if not explicitly provided
        if fundamentals_csv_path is None and config.csv_path is not None:
            fundamentals_csv_path = str(config.csv_path)
    
    # Handle finagg source
    if source == "finagg":
        logger.info("Using finagg SEC EDGAR as fundamentals source")
        mode = config.finagg_mode if config else "quarterly_refined"
        return _load_fundamentals_from_finagg(tickers, start, end, mode=mode)
    
    # Handle yfinance source
    if source == "yfinance":
        logger.info("Using yfinance as fundamentals source")
        try:
            return _load_fundamentals_from_yfinance(tickers, start, end)
        except Exception as e:
            logger.warning(f"Failed to load from yfinance: {e}. Using placeholder.")
            return _create_placeholder_fundamentals(tickers, start, end)
    
    # Default: CSV source with fallbacks
    # Priority 1: CSV file
    if fundamentals_csv_path is not None:
        path = Path(fundamentals_csv_path)
        if path.exists():
            return _load_fundamentals_from_csv(path, tickers, start, end)
        else:
            logger.warning(
                f"Fundamentals CSV not found at {path}. Trying yfinance."
            )

    # Priority 2: yfinance
    if use_yfinance:
        try:
            return _load_fundamentals_from_yfinance(tickers, start, end)
        except Exception as e:
            logger.warning(f"Failed to load from yfinance: {e}. Using placeholder.")

    # Priority 3: Placeholder
    logger.info("Using placeholder fundamental data (all NaN).")
    return _create_placeholder_fundamentals(tickers, start, end)


def _load_fundamentals_from_yfinance(
    tickers: list[str],
    start: str,
    end: str,
) -> pd.DataFrame:
    """
    Load HISTORICAL fundamental data from yfinance financial statements.

    Uses quarterly income statements and balance sheets to construct
    point-in-time fundamentals. Data is lagged by ~60 days to simulate
    the delay between fiscal quarter end and when data becomes available.

    LIMITATIONS:
    - yfinance only provides the last 4-5 quarters of financial data
    - For dates before available data, the earliest available data is used
    - This means older backtest periods may have limited fundamental coverage

    For deep historical backtests (>1 year back), consider using a paid
    point-in-time database like SimFin, Compustat, or Refinitiv.

    Args:
        tickers: List of ticker symbols.
        start: Start date.
        end: End date.

    Returns:
        DataFrame with MultiIndex (date, ticker) and fundamental columns.
    """
    import yfinance as yf

    logger.info(f"Fetching historical fundamentals from yfinance for {len(tickers)} tickers...")
    logger.info(
        "Note: yfinance provides ~4-5 quarters of historical data. "
        "Earlier periods will use the oldest available data."
    )

    # We'll collect quarterly data points and forward-fill to monthly
    all_quarterly_records: list[dict] = []

    for ticker in tickers:
        try:
            yf_ticker = yf.Ticker(ticker)
            quarterly_records = _extract_quarterly_fundamentals(yf_ticker, ticker)
            all_quarterly_records.extend(quarterly_records)
        except Exception as e:
            logger.warning(f"Failed to fetch fundamentals for {ticker}: {e}")

    if not all_quarterly_records:
        logger.warning("No historical fundamentals retrieved. Using placeholder.")
        return _create_placeholder_fundamentals(tickers, start, end)

    # Build DataFrame from quarterly records
    df_quarterly = pd.DataFrame(all_quarterly_records)
    df_quarterly["date"] = pd.to_datetime(df_quarterly["date"])
    df_quarterly = df_quarterly.set_index(["date", "ticker"]).sort_index()

    # Forward-fill to monthly frequency for each ticker
    df = _expand_quarterly_to_monthly(df_quarterly, tickers, start, end)

    # Ensure all expected columns exist
    for col in RAW_FUNDAMENTAL_COLUMNS:
        if col not in df.columns:
            df[col] = np.nan

    n_tickers_with_data = df.groupby("ticker").size().gt(0).sum()
    logger.info(
        f"Loaded historical fundamentals for {n_tickers_with_data} tickers "
        f"across {df.index.get_level_values('date').nunique()} dates"
    )

    return df[RAW_FUNDAMENTAL_COLUMNS]


def _extract_quarterly_fundamentals(
    yf_ticker,
    ticker: str,
) -> list[dict]:
    """
    Extract quarterly fundamental data from yfinance Ticker object.

    Pulls from quarterly_income_stmt, quarterly_balance_sheet, and info
    to compute metrics. Applies a ~60 day publication lag.

    Args:
        yf_ticker: yfinance Ticker object.
        ticker: Ticker symbol string.

    Returns:
        List of dicts with quarterly fundamental snapshots.
    """
    records = []

    # Get quarterly statements (columns are dates, rows are line items)
    try:
        income_stmt = yf_ticker.quarterly_income_stmt
        balance_sheet = yf_ticker.quarterly_balance_sheet
    except Exception:
        return records

    if income_stmt is None or income_stmt.empty:
        return records

    # Get fiscal quarter end dates (columns)
    quarter_dates = income_stmt.columns

    for q_date in quarter_dates:
        try:
            # Publication lag: fundamentals aren't available until ~60 days after quarter end
            available_date = q_date + pd.Timedelta(days=60)

            # Extract income statement items
            revenue = _safe_get_item(income_stmt, q_date, ["Total Revenue", "Revenue"])
            gross_profit = _safe_get_item(income_stmt, q_date, ["Gross Profit"])
            operating_income = _safe_get_item(income_stmt, q_date, ["Operating Income", "EBIT"])
            net_income = _safe_get_item(income_stmt, q_date, ["Net Income", "Net Income Common Stockholders"])
            eps = _safe_get_item(income_stmt, q_date, ["Basic EPS", "Diluted EPS"])

            # Extract balance sheet items
            total_assets = np.nan
            total_equity = np.nan
            if balance_sheet is not None and not balance_sheet.empty and q_date in balance_sheet.columns:
                total_assets = _safe_get_item(balance_sheet, q_date, ["Total Assets"])
                total_equity = _safe_get_item(
                    balance_sheet, q_date,
                    ["Total Stockholders Equity", "Stockholders Equity", "Total Equity Gross Minority Interest"]
                )

            # Compute TTM (trailing twelve months) by summing last 4 quarters
            # For simplicity, we'll use single quarter * 4 as approximation
            revenue_ttm = revenue * 4 if pd.notna(revenue) else np.nan
            net_income_ttm = net_income * 4 if pd.notna(net_income) else np.nan
            eps_ttm = eps * 4 if pd.notna(eps) else np.nan

            # Compute ratios
            gross_margin = (gross_profit / revenue) if pd.notna(gross_profit) and pd.notna(revenue) and revenue != 0 else np.nan
            operating_margin = (operating_income / revenue) if pd.notna(operating_income) and pd.notna(revenue) and revenue != 0 else np.nan
            net_margin = (net_income / revenue) if pd.notna(net_income) and pd.notna(revenue) and revenue != 0 else np.nan
            roe = (net_income_ttm / total_equity) if pd.notna(net_income_ttm) and pd.notna(total_equity) and total_equity != 0 else np.nan
            roa = (net_income_ttm / total_assets) if pd.notna(net_income_ttm) and pd.notna(total_assets) and total_assets != 0 else np.nan

            record = {
                "date": available_date,
                "ticker": ticker,
                "market_cap": np.nan,  # Will be filled from price data if needed
                "pe_ratio": np.nan,  # Requires price, computed downstream
                "pb_ratio": np.nan,  # Requires price, computed downstream
                "ps_ratio": np.nan,  # Requires price, computed downstream
                "dividend_yield": np.nan,  # Not easily available historically
                "roe": roe,
                "roa": roa,
                "gross_margin": gross_margin,
                "operating_margin": operating_margin,
                "net_margin": net_margin,
                "revenue_ttm": revenue_ttm,
                "revenue_growth_1y": np.nan,  # Computed below after we have history
                "eps_ttm": eps_ttm,
                "eps_growth_1y": np.nan,  # Computed below after we have history
            }
            records.append(record)

        except Exception as e:
            logger.debug(f"Error processing quarter {q_date} for {ticker}: {e}")
            continue

    # Compute YoY growth rates if we have enough history
    if len(records) >= 5:
        # Sort by date
        records = sorted(records, key=lambda x: x["date"])
        for i in range(4, len(records)):
            current = records[i]
            prior = records[i - 4]  # 4 quarters ago

            if pd.notna(current["revenue_ttm"]) and pd.notna(prior["revenue_ttm"]) and prior["revenue_ttm"] != 0:
                current["revenue_growth_1y"] = (current["revenue_ttm"] / prior["revenue_ttm"]) - 1

            if pd.notna(current["eps_ttm"]) and pd.notna(prior["eps_ttm"]) and prior["eps_ttm"] != 0:
                current["eps_growth_1y"] = (current["eps_ttm"] / prior["eps_ttm"]) - 1

    return records


def _safe_get_item(
    df: pd.DataFrame,
    col,
    row_names: list[str],
) -> float:
    """
    Safely extract a value from a financial statement DataFrame.

    Tries multiple possible row names (different tickers use different labels).

    Args:
        df: Financial statement DataFrame (rows=line items, cols=dates).
        col: Column (date) to extract from.
        row_names: List of possible row names to try.

    Returns:
        Float value or np.nan if not found.
    """
    for name in row_names:
        if name in df.index:
            val = df.loc[name, col]
            if pd.notna(val):
                return float(val)
    return np.nan


def _expand_quarterly_to_monthly(
    df_quarterly: pd.DataFrame,
    tickers: list[str],
    start: str,
    end: str,
) -> pd.DataFrame:
    """
    Expand quarterly fundamental data to monthly frequency via forward-fill.

    This simulates point-in-time data: each month uses the most recent
    available quarterly data as of that date.

    For dates before any available data, the earliest available data is used
    (backfill). This is a compromise for yfinance's limited history.

    Args:
        df_quarterly: DataFrame with quarterly data, MultiIndex (date, ticker).
        tickers: List of all tickers to include.
        start: Start date for monthly range.
        end: End date for monthly range.

    Returns:
        DataFrame with monthly data, MultiIndex (date, ticker).
    """
    # Create monthly date range
    monthly_dates = pd.date_range(start, end, freq="ME")

    all_records = []

    for ticker in tickers:
        # Get quarterly data for this ticker
        try:
            ticker_data = df_quarterly.xs(ticker, level="ticker")
        except KeyError:
            # No data for this ticker, create NaN rows
            for date in monthly_dates:
                record = {"date": date, "ticker": ticker}
                for col in RAW_FUNDAMENTAL_COLUMNS:
                    record[col] = np.nan
                all_records.append(record)
            continue

        if ticker_data.empty:
            for date in monthly_dates:
                record = {"date": date, "ticker": ticker}
                for col in RAW_FUNDAMENTAL_COLUMNS:
                    record[col] = np.nan
                all_records.append(record)
            continue

        # Reindex to monthly and forward-fill (with backfill for dates before earliest data)
        ticker_data = ticker_data.sort_index()
        earliest_data = ticker_data.iloc[0]  # For backfilling

        for date in monthly_dates:
            # Get most recent available data as of this date
            available = ticker_data[ticker_data.index <= date]
            if available.empty:
                # Use earliest available data for backfill
                record = {"date": date, "ticker": ticker}
                for col in RAW_FUNDAMENTAL_COLUMNS:
                    record[col] = earliest_data.get(col, np.nan)
            else:
                latest = available.iloc[-1]
                record = {"date": date, "ticker": ticker}
                for col in RAW_FUNDAMENTAL_COLUMNS:
                    record[col] = latest.get(col, np.nan)
            all_records.append(record)

    df = pd.DataFrame(all_records)
    df["date"] = pd.to_datetime(df["date"])
    df = df.set_index(["date", "ticker"]).sort_index()

    return df


def _load_fundamentals_from_csv(
    path: Path,
    tickers: list[str],
    start: str,
    end: str,
) -> pd.DataFrame:
    """
    Load fundamental data from a CSV file.

    Args:
        path: Path to the CSV file.
        tickers: List of tickers to filter.
        start: Start date.
        end: End date.

    Returns:
        DataFrame with MultiIndex (date, ticker).
    """
    df = pd.read_csv(path, parse_dates=["date"])

    # Filter by tickers and date range
    df = df[df["ticker"].isin(tickers)]
    df = df[(df["date"] >= start) & (df["date"] <= end)]

    # Set MultiIndex
    df = df.set_index(["date", "ticker"]).sort_index()

    # Ensure all expected columns exist
    for col in RAW_FUNDAMENTAL_COLUMNS:
        if col not in df.columns:
            df[col] = np.nan
            logger.warning(f"Column '{col}' not in CSV, filling with NaN")

    return df[RAW_FUNDAMENTAL_COLUMNS]


def _create_placeholder_fundamentals(
    tickers: list[str],
    start: str,
    end: str,
) -> pd.DataFrame:
    """
    Create a placeholder DataFrame with NaN values.

    This allows downstream code to work without real fundamental data.
    All fundamental factors will be NaN and will be dropped during alignment.

    Args:
        tickers: List of ticker symbols.
        start: Start date.
        end: End date.

    Returns:
        DataFrame with MultiIndex (date, ticker) and NaN values.
    """
    # Create monthly date range (fundamentals typically update monthly/quarterly)
    dates = pd.date_range(start, end, freq="ME")

    # Create MultiIndex
    idx = pd.MultiIndex.from_product([dates, tickers], names=["date", "ticker"])

    # Create DataFrame with NaN values
    df = pd.DataFrame(index=idx, columns=RAW_FUNDAMENTAL_COLUMNS, dtype=float)

    return df


# =============================================================================
# Module-level cache for finagg data to avoid repeated API calls
# =============================================================================
_FINAGG_CACHE: dict[str, pd.DataFrame] = {}


def _load_fundamentals_from_finagg(
    tickers: list[str],
    start: str,
    end: str,
    mode: str = "quarterly_refined",
) -> pd.DataFrame:
    """
    Load fundamental data from SEC EDGAR via finagg or direct API.

    This function first tries finagg, then falls back to direct SEC API
    for better ticker coverage. Results are cached to avoid repeated API calls.

    Args:
        tickers: List of ticker symbols.
        start: Start date in 'YYYY-MM-DD' format.
        end: End date in 'YYYY-MM-DD' format.
        mode: Finagg mode ("quarterly_refined", "quarterly_api", "annual_refined").

    Returns:
        DataFrame with MultiIndex (date, ticker) and fundamental columns.

    Raises:
        RuntimeError: If SEC data cannot be fetched.
    """
    global _FINAGG_CACHE
    
    # Create cache key
    cache_key = f"{'-'.join(sorted(tickers))}_{start}_{end}_{mode}"
    
    # Check cache first
    if cache_key in _FINAGG_CACHE:
        logger.debug("Using cached finagg data")
        cached_df = _FINAGG_CACHE[cache_key]
        # Filter to requested date range
        start_ts = pd.Timestamp(start)
        end_ts = pd.Timestamp(end)
        mask = (cached_df.index.get_level_values("date") >= start_ts) & \
               (cached_df.index.get_level_values("date") <= end_ts)
        return cached_df.loc[mask].copy()
    
    # Try to import finagg modules
    try:
        from auto_researcher.data.finagg_fundamentals import (
            fetch_finagg_quarterly_fundamentals,
            fetch_sec_fundamentals_direct,
        )
    except ImportError as e:
        raise RuntimeError(
            "finagg_fundamentals module not found. "
            "Ensure auto_researcher is properly installed."
        ) from e
    
    # Parse mode to get the fetch mode
    if mode.startswith("quarterly_"):
        fetch_mode = mode.replace("quarterly_", "")  # "refined" or "api"
    else:
        fetch_mode = "refined"  # Default for annual
    
    logger.info(f"Loading SEC fundamentals via finagg (mode={mode})")
    
    # First, try finagg 
    finagg_df = fetch_finagg_quarterly_fundamentals(
        tickers=tickers,
        start=pd.Timestamp(start),
        end=pd.Timestamp(end),
        mode=fetch_mode,
    )
    
    # Check how many tickers we got from finagg
    finagg_tickers = set()
    if not finagg_df.empty:
        finagg_tickers = set(finagg_df.index.get_level_values('ticker').unique())
    
    missing_tickers = set(tickers) - finagg_tickers
    
    # If finagg missed many tickers, use direct SEC API for the rest
    if missing_tickers:
        logger.info(
            f"Finagg returned {len(finagg_tickers)} tickers. "
            f"Fetching {len(missing_tickers)} more via direct SEC API..."
        )
        
        direct_df = fetch_sec_fundamentals_direct(
            tickers=list(missing_tickers),
            start=pd.Timestamp(start),
            end=pd.Timestamp(end),
        )
        
        # Combine finagg and direct data
        if not direct_df.empty:
            if not finagg_df.empty:
                finagg_df = pd.concat([finagg_df, direct_df], axis=0)
            else:
                finagg_df = direct_df
    
    if finagg_df.empty:
        logger.warning("No data returned from SEC, using placeholder")
        return _create_placeholder_fundamentals(tickers, start, end)
    
    # The finagg data already has the columns we need for factor computation:
    # - roe, roa (quality)
    # - debt_equity, quick_ratio, asset_coverage (quality)
    # - asset_growth, equity_growth, inventory_growth (growth)
    # - gross_margin, operating_margin, net_margin (profitability - may be NaN)
    # - book_ratio, pb_ratio (value)
    
    # Just add any missing standard columns with NaN
    result = finagg_df.copy()
    
    # Add columns needed by other factor families if not present
    standard_cols = [
        "market_cap", "pe_ratio", "pb_ratio", "ps_ratio", "dividend_yield",
        "revenue_ttm", "eps_ttm", "revenue_growth_1y", "eps_growth_1y",
        "gross_margin", "operating_margin", "net_margin", "roe", "roa",
    ]
    for col in standard_cols:
        if col not in result.columns:
            result[col] = np.nan
    
    # Cache the result for future calls
    _FINAGG_CACHE[cache_key] = result.copy()
    
    logger.info(
        f"Loaded finagg fundamentals: {len(result)} records, "
        f"{result.index.get_level_values('ticker').nunique()} tickers"
    )
    
    return result


def _compute_yoy_growth(df: pd.DataFrame, column: str) -> pd.Series:
    """
    Compute year-over-year growth rate for a column.

    Uses 4-quarter lag to compare same quarter YoY.

    Args:
        df: DataFrame with MultiIndex (date, ticker).
        column: Column name to compute growth for.

    Returns:
        Series with YoY growth rates.
    """
    if column not in df.columns:
        return pd.Series(np.nan, index=df.index)
    
    result = pd.Series(np.nan, index=df.index)
    
    for ticker in df.index.get_level_values("ticker").unique():
        try:
            ticker_data = df.xs(ticker, level="ticker")[column].sort_index()
            # Shift by 4 quarters (approximately 1 year)
            if len(ticker_data) >= 5:
                prior = ticker_data.shift(4)
                growth = (ticker_data / prior) - 1
                growth = growth.replace([np.inf, -np.inf], np.nan)
                
                # Map back to MultiIndex
                for date, value in growth.items():
                    if (date, ticker) in result.index:
                        result.loc[(date, ticker)] = value
        except Exception:
            continue
    
    return result


# =============================================================================
# Factor Computation Functions
# =============================================================================


def compute_value_factors(
    raw_fund: pd.DataFrame,
    prices: pd.DataFrame | None = None,
) -> pd.DataFrame:
    """
    Compute value factors from raw fundamentals.

    Value factors capture cheapness/expensiveness of stocks relative to
    their fundamentals. Higher values generally indicate undervaluation.

    Computed factors:
        - value_ey: Earnings yield = 1 / PE ratio  (or EPS/price)
        - value_btp: Book-to-price = 1 / PB ratio (or book_value/price)
        - value_stp: Sales-to-price = 1 / PS ratio (or sales_per_share/price)

    Args:
        raw_fund: DataFrame with MultiIndex (date, ticker) and columns
            including pe_ratio, pb_ratio, ps_ratio OR eps_basic, 
            book_value_per_share, revenue, shares_outstanding.
        prices: Optional DataFrame with price data (index=date, columns=tickers).
            Required if computing from raw SEC data without pre-computed ratios.

    Returns:
        DataFrame with MultiIndex (date, ticker) and value factor columns.
    """
    result = pd.DataFrame(index=raw_fund.index)

    # Try to use pre-computed ratios first (from CSV/yfinance)
    # Check both presence AND non-empty data (columns may exist but be all NaN)
    precomputed_cols = ['pe_ratio', 'pb_ratio', 'ps_ratio']
    has_precomputed = all(
        col in raw_fund.columns and raw_fund[col].notna().any()
        for col in precomputed_cols
    )
    
    if has_precomputed:
        # Earnings yield = 1 / P/E (handle negative P/E by keeping as-is)
        pe = raw_fund["pe_ratio"].replace(0, np.nan)
        result["value_ey"] = 1.0 / pe

        # Book-to-price = 1 / P/B
        pb = raw_fund["pb_ratio"].replace(0, np.nan)
        result["value_btp"] = 1.0 / pb

        # Sales-to-price = 1 / P/S
        ps = raw_fund["ps_ratio"].replace(0, np.nan)
        result["value_stp"] = 1.0 / ps
    else:
        # Compute from raw SEC data if prices are available
        # EPS is already per-share, just need to divide by price
        if "eps_basic" in raw_fund.columns:
            # Earnings yield = EPS / Price
            # For now, just use EPS as a proxy (will be combined with price later)
            # This gives us the numerator; division by price happens at alignment
            result["value_ey"] = raw_fund["eps_basic"]
            logger.debug("Using eps_basic for value_ey (raw, not ratio)")
        elif "net_income" in raw_fund.columns and "shares_outstanding" in raw_fund.columns:
            # Fallback: compute EPS from net_income / shares
            with np.errstate(divide='ignore', invalid='ignore'):
                result["value_ey"] = raw_fund["net_income"] / raw_fund["shares_outstanding"]
                result["value_ey"] = result["value_ey"].replace([np.inf, -np.inf], np.nan)
            logger.debug("Computed value_ey from net_income/shares_outstanding")
        
        if "book_value_per_share" in raw_fund.columns:
            # Book value per share (numerator for B/P)
            result["value_btp"] = raw_fund["book_value_per_share"]
            logger.debug("Using book_value_per_share for value_btp (raw, not ratio)")
        elif "stockholders_equity" in raw_fund.columns and "shares_outstanding" in raw_fund.columns:
            # Fallback: compute BVPS from equity / shares
            with np.errstate(divide='ignore', invalid='ignore'):
                result["value_btp"] = raw_fund["stockholders_equity"] / raw_fund["shares_outstanding"]
                result["value_btp"] = result["value_btp"].replace([np.inf, -np.inf], np.nan)
            logger.debug("Computed value_btp from stockholders_equity/shares_outstanding")
        
        if "revenue" in raw_fund.columns and "shares_outstanding" in raw_fund.columns:
            # Sales per share (numerator for S/P)
            with np.errstate(divide='ignore', invalid='ignore'):
                result["value_stp"] = raw_fund["revenue"] / raw_fund["shares_outstanding"]
                result["value_stp"] = result["value_stp"].replace([np.inf, -np.inf], np.nan)
            logger.debug("Computed value_stp from revenue/shares_outstanding")

    return result


def compute_quality_factors(raw_fund: pd.DataFrame) -> pd.DataFrame:
    """
    Compute quality factors from raw fundamentals.

    Quality factors measure the fundamental strength and stability of
    a company's business. Higher values indicate higher quality.

    Computed factors:
        - quality_roe: Return on equity
        - quality_roa: Return on assets
        - quality_net_margin: Net profit margin (if available)
        - quality_debt_equity: Debt to equity ratio (inverted, lower is better)
        - quality_quick_ratio: Quick ratio (liquidity)

    Args:
        raw_fund: DataFrame with MultiIndex (date, ticker) and columns
            including roe, roa, net_margin, debt_equity, quick_ratio.

    Returns:
        DataFrame with MultiIndex (date, ticker) and quality factor columns.
    """
    result = pd.DataFrame(index=raw_fund.index)

    # Core quality metrics
    if "roe" in raw_fund.columns:
        result["quality_roe"] = raw_fund["roe"]
    
    if "roa" in raw_fund.columns:
        result["quality_roa"] = raw_fund["roa"]
    
    if "net_margin" in raw_fund.columns:
        result["quality_net_margin"] = raw_fund["net_margin"]
    
    # Additional quality metrics from finagg
    if "debt_equity" in raw_fund.columns:
        # Invert so lower debt = higher quality score
        result["quality_low_leverage"] = -raw_fund["debt_equity"]
    
    if "quick_ratio" in raw_fund.columns:
        result["quality_liquidity"] = raw_fund["quick_ratio"]
    
    if "asset_coverage" in raw_fund.columns:
        result["quality_asset_coverage"] = raw_fund["asset_coverage"]

    return result


def compute_growth_factors(raw_fund: pd.DataFrame) -> pd.DataFrame:
    """
    Compute growth factors from raw fundamentals.

    Growth factors capture the rate of change in key financial metrics.
    Higher values indicate faster-growing companies.

    Computed factors:
        - growth_rev_1y: 1-year revenue growth rate (if available)
        - growth_eps_1y: 1-year earnings per share growth rate (if available)
        - growth_assets: Asset growth (from finagg LOG_CHANGE or computed)
        - growth_equity: Stockholders equity growth

    Args:
        raw_fund: DataFrame with MultiIndex (date, ticker) and columns
            including revenue_growth_1y, eps_growth_1y, asset_growth, equity_growth
            OR revenue, total_assets, stockholders_equity, net_income for computation.

    Returns:
        DataFrame with MultiIndex (date, ticker) and growth factor columns.
    """
    result = pd.DataFrame(index=raw_fund.index)

    # Traditional growth metrics (from CSV/yfinance sources)
    if "revenue_growth_1y" in raw_fund.columns:
        result["growth_rev_1y"] = raw_fund["revenue_growth_1y"]
    elif "revenue" in raw_fund.columns:
        # Compute YoY growth from raw revenue
        # Sort by ticker and date to compute pct_change correctly
        result["growth_rev_1y"] = _compute_yoy_growth(raw_fund, "revenue")
        logger.debug("Computed growth_rev_1y from revenue time series")
    
    if "eps_growth_1y" in raw_fund.columns:
        result["growth_eps_1y"] = raw_fund["eps_growth_1y"]
    elif "net_income" in raw_fund.columns:
        # Compute YoY growth from net income as proxy
        result["growth_eps_1y"] = _compute_yoy_growth(raw_fund, "net_income")
        logger.debug("Computed growth_eps_1y from net_income time series")
    
    # Growth metrics from finagg (LOG_CHANGE columns)
    if "asset_growth" in raw_fund.columns:
        result["growth_assets"] = raw_fund["asset_growth"]
    elif "total_assets" in raw_fund.columns:
        result["growth_assets"] = _compute_yoy_growth(raw_fund, "total_assets")
        logger.debug("Computed growth_assets from total_assets time series")
    
    if "equity_growth" in raw_fund.columns:
        result["growth_equity"] = raw_fund["equity_growth"]
    elif "stockholders_equity" in raw_fund.columns:
        result["growth_equity"] = _compute_yoy_growth(raw_fund, "stockholders_equity")
        logger.debug("Computed growth_equity from stockholders_equity time series")
    
    if "inventory_growth" in raw_fund.columns:
        # Negative inventory growth can indicate efficiency
        result["growth_inventory"] = raw_fund["inventory_growth"]

    return result


def _compute_yoy_growth(
    df: pd.DataFrame,
    col: str,
) -> pd.Series:
    """
    Compute year-over-year growth for a column.
    
    Compares each quarter to the same quarter from the previous year
    (4 quarters ago) to avoid seasonality issues.
    
    Args:
        df: DataFrame with MultiIndex (date, ticker).
        col: Column name to compute growth for.
    
    Returns:
        Series with YoY growth rates.
    """
    if col not in df.columns:
        return pd.Series(np.nan, index=df.index)
    
    result = pd.Series(np.nan, index=df.index)
    
    # Group by ticker and compute pct change vs 4 quarters ago
    for ticker in df.index.get_level_values("ticker").unique():
        mask = df.index.get_level_values("ticker") == ticker
        ticker_data = df.loc[mask, col].sort_index()
        
        if len(ticker_data) >= 5:  # Need at least 5 quarters for 4-quarter lag
            # Compute YoY growth: (current - year_ago) / year_ago
            growth = ticker_data.pct_change(periods=4)
            result.loc[mask] = growth.values
    
    # Cap extreme values
    result = result.clip(-2.0, 5.0)  # Cap at -200% to +500%
    return result


def compute_profitability_factors(raw_fund: pd.DataFrame) -> pd.DataFrame:
    """
    Compute profitability factors from raw fundamentals.

    Profitability factors measure a company's ability to generate profit
    from its operations. Higher values indicate more efficient operations.

    Computed factors:
        - prof_gross_margin: Gross profit margin (if available)
        - prof_op_margin: Operating profit margin (if available)
        - prof_roe: Return on equity (alternative profitability measure)
        - prof_roa: Return on assets (alternative profitability measure)

    Args:
        raw_fund: DataFrame with MultiIndex (date, ticker) and columns
            including gross_margin, operating_margin, roe, roa.

    Returns:
        DataFrame with MultiIndex (date, ticker) and profitability factor columns.
    """
    result = pd.DataFrame(index=raw_fund.index)

    has_margins = False
    
    # Traditional margin metrics
    if "gross_margin" in raw_fund.columns and raw_fund["gross_margin"].notna().any():
        result["prof_gross_margin"] = raw_fund["gross_margin"]
        has_margins = True
    
    if "operating_margin" in raw_fund.columns and raw_fund["operating_margin"].notna().any():
        result["prof_op_margin"] = raw_fund["operating_margin"]
        has_margins = True
    
    # ROE/ROA as profitability proxies when margins aren't available
    if not has_margins:
        if "roe" in raw_fund.columns:
            result["prof_roe"] = raw_fund["roe"]
        
        if "roa" in raw_fund.columns:
            result["prof_roa"] = raw_fund["roa"]

    return result


def compute_size_factor(raw_fund: pd.DataFrame) -> pd.DataFrame:
    """
    Compute size factor from raw fundamentals.

    Size factor captures the market capitalization effect. Historically,
    smaller companies have outperformed larger ones on a risk-adjusted basis.

    Computed factors:
        - size_log_mktcap: Natural log of market capitalization

    Note:
        The sign convention for size is often debated. We use log(market_cap)
        directly, so higher values = larger companies. If you want a "small
        minus big" factor, negate this value.

    Args:
        raw_fund: DataFrame with MultiIndex (date, ticker) and column market_cap
            OR total_assets (as size proxy for SEC data).

    Returns:
        DataFrame with MultiIndex (date, ticker) and size factor column.
    """
    result = pd.DataFrame(index=raw_fund.index)

    # Prefer market_cap if available (from CSV/yfinance)
    if "market_cap" in raw_fund.columns:
        mktcap = raw_fund["market_cap"].replace(0, np.nan)
        mktcap = mktcap.where(mktcap > 0, np.nan)
        result["size_log_mktcap"] = np.log(mktcap)
    elif "total_assets" in raw_fund.columns:
        # Fallback: use log(total_assets) as size proxy
        # Not as good as market cap, but reasonable for SEC data
        assets = raw_fund["total_assets"].replace(0, np.nan)
        assets = assets.where(assets > 0, np.nan)
        result["size_log_mktcap"] = np.log(assets)
        logger.debug("Using total_assets as size proxy (market_cap not available)")
    else:
        logger.warning("No size metric available (market_cap or total_assets)")

    return result


# =============================================================================
# Helper Functions for Cross-Sectional Processing
# =============================================================================


def _winsorize_cross_sectional(
    df: pd.DataFrame,
    pct: float,
) -> pd.DataFrame:
    """
    Winsorize values cross-sectionally (by date).

    For each date, clips values to [pct, 1-pct] percentile range.

    Args:
        df: DataFrame with MultiIndex (date, ticker).
        pct: Percentile for clipping (e.g., 0.01 for 1%).

    Returns:
        Winsorized DataFrame with same structure.
    """
    if pct <= 0:
        return df

    def winsorize_group(group: pd.DataFrame) -> pd.DataFrame:
        lower = group.quantile(pct)
        upper = group.quantile(1 - pct)
        return group.clip(lower=lower, upper=upper, axis=1)

    return df.groupby(level="date", group_keys=False).apply(winsorize_group)


def _zscore_cross_sectional(df: pd.DataFrame) -> pd.DataFrame:
    """
    Z-score normalize values cross-sectionally (by date).

    For each date, transforms values to have mean=0 and std=1.

    Args:
        df: DataFrame with MultiIndex (date, ticker).

    Returns:
        Z-scored DataFrame with same structure.
    """

    def zscore_group(group: pd.DataFrame) -> pd.DataFrame:
        mean = group.mean()
        std = group.std()
        # Avoid division by zero
        std = std.replace(0, np.nan)
        return (group - mean) / std

    return df.groupby(level="date", group_keys=False).apply(zscore_group)


# =============================================================================
# Main Factor Builder
# =============================================================================


def build_fundamental_factors(
    raw_fund: pd.DataFrame,
    config: FundamentalFactorConfig | None = None,
) -> pd.DataFrame:
    """
    Build fundamental factor matrix from raw fundamental data.

    This function:
    1. Computes each enabled factor family
    2. Concatenates them into a single wide DataFrame
    3. Optionally winsorizes extreme values
    4. Optionally z-scores cross-sectionally

    Args:
        raw_fund: DataFrame with MultiIndex (date, ticker) and raw fundamental
            columns (market_cap, pe_ratio, etc.).
        config: Configuration specifying which factors to include and
            how to process them. Uses defaults if not provided.

    Returns:
        DataFrame with MultiIndex (date, ticker) and factor columns like:
            value_ey, value_btp, quality_roe, growth_rev_1y, size_log_mktcap, etc.

    Example:
        >>> raw_fund = load_raw_fundamentals(['AAPL', 'MSFT'], '2023-01-01', '2024-01-01')
        >>> config = FundamentalFactorConfig(use_size=False)  # Exclude size
        >>> factors = build_fundamental_factors(raw_fund, config)
        >>> 'size_log_mktcap' in factors.columns
        False
    """
    if config is None:
        config = FundamentalFactorConfig()

    factor_dfs = []

    # Compute selected factor families
    if config.use_value:
        factor_dfs.append(compute_value_factors(raw_fund))

    if config.use_quality:
        factor_dfs.append(compute_quality_factors(raw_fund))

    if config.use_growth:
        factor_dfs.append(compute_growth_factors(raw_fund))

    if config.use_profitability:
        factor_dfs.append(compute_profitability_factors(raw_fund))

    if config.use_size:
        factor_dfs.append(compute_size_factor(raw_fund))

    if not factor_dfs:
        logger.warning("No fundamental factor families enabled, returning empty DataFrame")
        return pd.DataFrame(index=raw_fund.index)

    # Concatenate all factors
    factors = pd.concat(factor_dfs, axis=1)

    # Apply winsorization
    if config.winsorize_pct > 0:
        factors = _winsorize_cross_sectional(factors, config.winsorize_pct)

    # Apply z-scoring
    if config.zscore_by_cross_section:
        factors = _zscore_cross_sectional(factors)

    return factors


# =============================================================================
# Legacy API (for backward compatibility)
# =============================================================================


def compute_value_features(
    fundamentals: pd.DataFrame,
    prices: pd.DataFrame,
) -> pd.DataFrame:
    """
    Legacy stub for value features. Use compute_value_factors instead.

    Args:
        fundamentals: Fundamental data DataFrame (unused in legacy mode).
        prices: Price data DataFrame.

    Returns:
        Empty DataFrame.
    """
    logger.warning("compute_value_features is deprecated - use compute_value_factors")
    return pd.DataFrame(index=prices.index)


def compute_growth_features(fundamentals: pd.DataFrame) -> pd.DataFrame:
    """
    Legacy stub for growth features. Use compute_growth_factors instead.

    Args:
        fundamentals: Fundamental data DataFrame.

    Returns:
        Empty DataFrame.
    """
    logger.warning("compute_growth_features is deprecated - use compute_growth_factors")
    return pd.DataFrame()


def compute_quality_features(fundamentals: pd.DataFrame) -> pd.DataFrame:
    """
    Legacy stub for quality features. Use compute_quality_factors instead.

    Args:
        fundamentals: Fundamental data DataFrame.

    Returns:
        Empty DataFrame.
    """
    logger.warning("compute_quality_features is deprecated - use compute_quality_factors")
    return pd.DataFrame()


def compute_all_fundamental_features(
    fundamentals: pd.DataFrame | None,
    prices: pd.DataFrame,
) -> pd.DataFrame:
    """
    Legacy stub for all fundamental features.

    Use load_raw_fundamentals + build_fundamental_factors instead.

    Args:
        fundamentals: Fundamental data (currently unused).
        prices: Price data for alignment.

    Returns:
        Empty DataFrame with correct index.
    """
    logger.warning(
        "compute_all_fundamental_features is deprecated - "
        "use load_raw_fundamentals + build_fundamental_factors"
    )
    return pd.DataFrame(index=prices.index)
